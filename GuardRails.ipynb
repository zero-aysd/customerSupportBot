{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b896ae5-974f-47c1-88bd-26c86d922ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import wandb\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "import openai\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6be9b9e-899e-4b60-b9fc-cae15655b6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Load API key\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# ✅ Cost per 1K tokens (USD)\n",
    "MODEL_PRICES = {\n",
    "    \"gpt-3.5-turbo\": 0.0015,\n",
    "    \"gpt-4.1-mini\": 0.00015,\n",
    "    \"gpt-4.1-nano\": 0.00000525\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c552e645-e46f-4670-abb9-f53077b2fc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ChatbotPrompts import GUARD_RAIL_TESTS, CUSTOMER_QUERIES, GUARDRAIL_DETECTOR_PROMPT, EVAL_PROMPT_TEMPLATE, FINAL_PROMPT_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ee5525c-6c11-4b76-83a2-98bf20898936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Pydantic model\n",
    "class GuardrailResult(BaseModel):\n",
    "    toxicity: bool\n",
    "    profanity: bool\n",
    "    prompt_injection: bool\n",
    "    issues: List[str]\n",
    "    summary: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2848c26-60d2-41b9-af31-336d67222e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Wrapper for OpenAI call\n",
    "def call_chat(model, messages, temperature=0.7, max_tokens=500):\n",
    "    start = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    latency = time.time() - start\n",
    "    usage = response.usage\n",
    "    content = response.choices[0].message.content\n",
    "    cost = (usage.prompt_tokens + usage.completion_tokens) / 1000 * MODEL_PRICES[model]\n",
    "    return content.strip(), usage, cost, latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d414e934-f709-4b73-b431-1a0999be1045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardrail checker function\n",
    "def check_guardrails(text: str, model=\"gpt-4.1-mini\") -> dict:\n",
    "    prompt = GUARDRAIL_DETECTOR_PROMPT.format(text=text)\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    raw_content = response.choices[0].message.content.strip()\n",
    "    print(\"Raw LLM response:\\n\", raw_content)\n",
    "    \n",
    "    # Clean markdown formatting (e.g., ```json ... ```)\n",
    "    cleaned_content = re.sub(r\"^```json\\n|\\n```$\", \"\", raw_content)\n",
    "\n",
    "    try:\n",
    "        result = GuardrailResult.model_validate_json(cleaned_content)\n",
    "        val = json.loads(result.model_dump_json())\n",
    "        return val\n",
    "    except ValidationError as e:\n",
    "        print(\"Pydantic validation error:\", e)\n",
    "        return {\n",
    "            \"toxicity\": False,\n",
    "            \"profanity\": False,\n",
    "            \"prompt_injection\": False,\n",
    "            \"issues\": [],\n",
    "            \"summary\": \"Invalid JSON or schema mismatch\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2faea6-3d9d-496b-9256-d66902d9007a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c704cf1-44da-431f-a9e3-428c6b9a030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Customer queries\n",
    "customer_queries = CUSTOMER_QUERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f760c5dd-69ac-487f-a6a9-0ee2d81d74ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: aayush-drishte (aayush-drishte-tredence) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.0s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\work\\LLMOPSchatbot\\wandb\\run-20250518_185107-bq68tcmk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aayush-drishte-tredence/customer-support-bot-GuardRails/runs/bq68tcmk' target=\"_blank\">customer-support-final-prompt-with guardrails</a></strong> to <a href='https://wandb.ai/aayush-drishte-tredence/customer-support-bot-GuardRails' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aayush-drishte-tredence/customer-support-bot-GuardRails' target=\"_blank\">https://wandb.ai/aayush-drishte-tredence/customer-support-bot-GuardRails</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aayush-drishte-tredence/customer-support-bot-GuardRails/runs/bq68tcmk' target=\"_blank\">https://wandb.ai/aayush-drishte-tredence/customer-support-bot-GuardRails/runs/bq68tcmk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Fatal error while uploading data. Some run data will not be synced, but it will still be written to disk. Use `wandb sync` at the end of the run to try uploading.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Init W&B\n",
    "run = wandb.init(\n",
    "    project=\"customer-support-bot-GuardRails\",\n",
    "    name=\"customer-support-final-prompt-with guardrails\",\n",
    "    config={\n",
    "        \"prompt_version\": \"finalized-v1\",\n",
    "        \"model\": \"gpt-4.1-mini\",\n",
    "        \"eval_model\": \"gpt-4.1-mini\",\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 500\n",
    "    },\n",
    "    save_code=True\n",
    ")\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8891deb-c14d-478b-a847-f3a38aef676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ W&B Table setup\n",
    "table = wandb.Table(columns=[\n",
    "    \"id\", \"persona\", \"category\", \"query\", \"chatbot_response\",\n",
    "    \"ground_helpfulness\", \"ground_correctness\", \"ground_tone\", \"ground_safety\",\n",
    "    \"eval_helpfulness\", \"eval_correctness\", \"eval_tone\", \"eval_clarity\",\n",
    "    \"eval_safety\", \"eval_toxicity\", \"eval_profanity\",\n",
    "    \"comment_helpfulness\", \"comment_correctness\", \"comment_tone\",\n",
    "    \"comment_clarity\", \"comment_safety\", \"comment_toxicity\", \"comment_profanity\",\n",
    "    \"overall_comment\", \"tokens_prompt\", \"tokens_completion\", \"tokens_total\", \"cost_usd\",\n",
    "    \"query_toxicity\", \"query_profanity\", \"query_prompt_injection\",\n",
    "    \"response_toxicity\", \"response_profanity\", \"response_prompt_injection\",\n",
    "    \"guardrail_summary\"\n",
    "])\n",
    "\n",
    "# ✅ Loop through queries\n",
    "for query in tqdm(customer_queries):\n",
    "    query_id = str(uuid.uuid4())\n",
    "\n",
    "    # Generate bot response\n",
    "    prompt = FINAL_PROMPT_TEMPLATE.format(customer_query=query)\n",
    "    bot_response, usage_gen, cost_gen, latency = call_chat(config.model, [{\"role\": \"user\", \"content\": prompt}])\n",
    "\n",
    "    # Evaluate\n",
    "    eval_prompt = EVAL_PROMPT_TEMPLATE.format(query=query, chatbot_response=bot_response)\n",
    "    eval_response, usage_eval, cost_eval, _ = call_chat(config.eval_model, [{\"role\": \"user\", \"content\": eval_prompt}], temperature=0.0)\n",
    "\n",
    "    try:\n",
    "        parsed = json.loads(eval_response)\n",
    "    except:\n",
    "        parsed = {}\n",
    "\n",
    "    get_score = lambda k: parsed.get(k, {}).get(\"score\", 0)\n",
    "    get_comment = lambda k: parsed.get(k, {}).get(\"comment\", \"\")\n",
    "\n",
    "    # Add to W&B table\n",
    "    table.add_data(\n",
    "        query_id, query, bot_response,\n",
    "        get_score(\"helpfulness\"), get_score(\"correctness\"), get_score(\"tone\"),\n",
    "        get_score(\"clarity\"), get_score(\"safety\"), get_score(\"toxicity\"),\n",
    "        get_score(\"profanity\"), parsed.get(\"overall_comment\", \"\"),\n",
    "        usage_gen.prompt_tokens, usage_gen.completion_tokens,\n",
    "        usage_gen.total_tokens, round(cost_gen + cost_eval, 6)\n",
    "    )\n",
    "\n",
    "    wandb.log({\n",
    "        \"query\": query,\n",
    "        \"helpfulness\": get_score(\"helpfulness\"),\n",
    "        \"correctness\": get_score(\"correctness\"),\n",
    "        \"safety\": get_score(\"safety\"),\n",
    "        \"clarity\": get_score(\"clarity\"),\n",
    "        \"toxicity\": get_score(\"toxicity\"),\n",
    "        \"cost_usd\": cost_gen + cost_eval,\n",
    "        \"latency\": latency\n",
    "    })\n",
    "\n",
    "# ✅ Finish logging\n",
    "wandb.log({\"eval_table\": table})\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
